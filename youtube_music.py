import os
import time
import glob
import re
import pandas as pd
from datetime import datetime, timedelta
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager 

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) í™˜ê²½ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DOWNLOAD_FOLDER   = os.path.join(os.getcwd(), "data", "ytweekly")
CSV_PATH          = os.path.join(os.getcwd(), "data", "us_weekly_yt.csv")
os.makedirs(DOWNLOAD_FOLDER, exist_ok=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) Selenium ì´ˆê¸°í™”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def init_driver():
    opts = Options()
    opts.add_experimental_option("prefs", {
        "download.default_directory": DOWNLOAD_FOLDER,
        "download.prompt_for_download": False,
        "download.directory_upgrade": True,
        "safebrowsing.enabled": True
    })
    opts.add_argument("--headless")   
    opts.add_argument("--disable-gpu")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_argument("--lang=en-US")
    opts.add_experimental_option("excludeSwitches", ["enable-automation"])
    opts.add_experimental_option("useAutomationExtension", False)

    # ChromeDriverManagerë¡œ ìë™ ì„¤ì¹˜ëœ ë“œë¼ì´ë²„ ì‚¬ìš©
    service = Service(ChromeDriverManager().install())
    return webdriver.Chrome(service=service, options=opts)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) ë§ˆì§€ë§‰ ëª©ìš”ì¼ ì´í›„ ë‚ ì§œ ê³„ì‚°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_next_thursdays(csv_path: str) -> list[str]:
    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"{csv_path} ì´ ì—†ìŠµë‹ˆë‹¤.")
    df = pd.read_csv(csv_path, dtype={'date': str})
    df['date'] = pd.to_datetime(df['date'], format="%Y%m%d")
    last_thu = df['date'].max()
    dates = []
    current = last_thu + timedelta(days=7)
    today   = datetime.today()
    while current < today:
        dates.append(current.strftime("%Y%m%d"))
        current += timedelta(days=7)
    return dates

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) ì°¨íŠ¸ í˜ì´ì§€ ì ‘ì† â†’ CSV ë‹¤ìš´ë¡œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def download_chart_for_date(driver, date_str: str):
    wait = WebDriverWait(driver, 10)
    url  = f"https://charts.youtube.com/charts/TopArtists/us/weekly/{date_str}"
    print(f"\nâ–¶ ì ‘ì†: {url}")
    driver.get(url)
    try:
        btn = wait.until(EC.element_to_be_clickable((
            By.XPATH,
            "/html/body/ytmc-v2-app/ytmc-detailed-page/div[1]/ytmc-top-banner/"
            "div[2]/div[4]/paper-icon-button[2]"
        )))
    except:
        btn = wait.until(EC.element_to_be_clickable((By.ID, "download-button")))
    btn.click()
    print(f"âœ… [{date_str}] ë‹¤ìš´ë¡œë“œ í´ë¦­")
    time.sleep(3)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5) CSV íŒŒì‹± ë³´ì¡°: artistì— ì‰¼í‘œê°€ ìˆì–´ë„ ì•ˆì „
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def parse_line(line: str) -> list[str]:
    parts = line.rstrip("\n").split(",")
    if len(parts) == 6:
        return parts
    rank, prev = parts[0], parts[1]
    growth     = parts[-1]
    views      = parts[-2]
    periods    = parts[-3]
    artist     = ",".join(parts[2:-3])
    return [rank, prev, artist, periods, views, growth]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 6) ìƒˆë¡œ ë°›ì€ íŒŒì¼ë“¤ì„ í†µí•©ë³¸ì— append
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def append_new_data(csv_path: str, download_folder: str, dates: list[str]):
    df_existing = pd.read_csv(csv_path, dtype={'date': str})

    merged = []
    for d in dates:
        pattern = os.path.join(download_folder, f"youtube-charts-top-artists-us-weekly-{d}.csv")
        if not os.path.exists(pattern):
            print(f"âš ï¸ {os.path.basename(pattern)} ì—†ìŒ, ê±´ë„ˆëœ€")
            continue

        with open(pattern, encoding="utf-8") as f:
            lines = [ln for ln in f.readlines() if ln.strip()]

        header = lines[0].strip().split(",")  
        rows   = [parse_line(ln) for ln in lines[1:]]

        df_new = pd.DataFrame(rows, columns=header)
        df_new.insert(0, "date", d)  
        merged.append(df_new)

    if not merged:
        print("ğŸš« ì¶”ê°€í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    df_all = pd.concat([df_existing] + merged, ignore_index=True)
    df_all.drop_duplicates(subset=["date", "Rank", "Artist Name"], inplace=True)
    df_all.to_csv(csv_path, index=False, encoding="utf-8-sig")
    total_new = sum(len(df) for df in merged)
    print(f"ğŸ“ {total_new}ê°œ ë ˆì½”ë“œ ì¶”ê°€ í›„ ì €ì¥: {csv_path}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 7) ë©”ì¸ ì‹¤í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    try:
        dates = get_next_thursdays(CSV_PATH)
        if not dates:
            print("âœ… ìµœì‹ ê¹Œì§€ ìˆ˜ì§‘ ì™„ë£Œ.")
        else:
            print(f"ğŸ“… ìˆ˜ì§‘í•  ì£¼ì°¨: {dates}")
            drv = init_driver()
            for dt in dates:
                download_chart_for_date(drv, dt)
            drv.quit()
            print("\nâœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ, ë¸Œë¼ìš°ì € ì¢…ë£Œ.")
            append_new_data(CSV_PATH, DOWNLOAD_FOLDER, dates)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")